{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image \n",
    "from keras.utils import to_categorical\n",
    "from numpy import array, argmax\n",
    "import random\n",
    "import h5py\n",
    "import cv2\n",
    "import gzip\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter notebook, we will generate datasets for digits classifier from the processed SVHN dataset. Also, we are going to generate a second dataset for a model which classifies how many digits number have in a given image. For the second dataset generation, besides the SVHN dataset, we will use other datasets that don't contain any digits, because we want to classify such images in our final approach. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 )  SVHN dataset preparation for classification model\n",
    "For further data preparation we use data preprocessed at [1__Preprocess.ipynb](1__Preprocess.ipynb) jupyter notebook.\n",
    "\n",
    "For training data images generation we'll do the same image preprocess as [Ian J. Goodfellow](https://arxiv.org/abs/1312.6082). Firstly, we are going to find the small rectangular bounding box that will contain individual character bounding boxes, then expand it by 30 % in all directions. Secondly, we'll crop the image to that bounding box and resize the crop to 64 × 64 pixels. Lastly, we'll crop a 54 × 54 pixel image from a random location within the 64 × 64 pixel image.<br>\n",
    "Also, we are going to normalize image by the equation: <br>\n",
    "<br>\n",
    "$ \\normalsize image_{norm} = \\frac{image - 127.5} {255} $\n",
    "\n",
    "We will augment data by repeating this process two times for every image and taking different number's location in the image in each repetition.\n",
    "For a training and validation dataset, we just crop areas surrounded by bounding boxes and resize them to 54 × 54 pixels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLenNumber(boxes):\n",
    "    if len(boxes) < 4:\n",
    "        return len(boxes)\n",
    "    else: \n",
    "        return 4\n",
    "    \n",
    "def generate_dataset(dataset, test = False, image_size = 64, length = False, grey = False):\n",
    "    \"test - true when generate validate/test dataser\"\n",
    "    \n",
    "    if grey:\n",
    "        num_channels = 1\n",
    "    else:\n",
    "        num_channels = 3\n",
    "    w = np.array([[[ 0.07, 0.72,  0.21]]])\n",
    "    pixel_depth = 255.0  # Number of levels per pixel.   \n",
    "    images = np.ndarray(shape=(len(dataset), image_size, image_size, num_channels),\n",
    "                         dtype=np.float32)\n",
    "    labels = np.ndarray(shape=(len(dataset), 3, 11))\n",
    "    if length:\n",
    "        length_labels = np.ndarray(shape=(len(dataset), 5)) \n",
    "    num_image = 0\n",
    "    \n",
    "    \n",
    "    for data in dataset:\n",
    "        \n",
    "        # Skip images with more then 5 digits\n",
    "        if len(data[\"boxes\"]) > 3 and not length:\n",
    "            continue\n",
    "        \n",
    "        # Read image\n",
    "        image_path = data['filename']\n",
    "        image_data = Image.open(image_path)\n",
    "        \n",
    "        # Get digits bounding boxes and labels\n",
    "        top = []; left = []; height = []; width = []; label = []\n",
    "        for box in data[\"boxes\"]:\n",
    "            top.append(box['top'])\n",
    "            left.append(box['left'])\n",
    "            height.append(box['height'])\n",
    "            width.append(box['width'])\n",
    "            if box[\"label\"] == 10:\n",
    "                label.append(0.0)\n",
    "            else:\n",
    "                label.append(box[\"label\"])\n",
    "            \n",
    "        # Get whole number bounding box\n",
    "        num_top = np.amin(top)\n",
    "        num_left = np.amin(left)\n",
    "        num_height = np.amax(top) + height[np.argmax(top)] - num_top\n",
    "        num_width = np.amax(left) + width[np.argmax(left)] - num_left  \n",
    "        \n",
    "           \n",
    "        if test is True:\n",
    "            image_data = image_data.crop((num_left, num_top,num_left + num_width, num_top + num_height)\\\n",
    "                                    ).resize([image_size,image_size])#.convert('L')\n",
    "        else:\n",
    "            # Expanding image by 30%\n",
    "            num_bottom = np.amin([np.ceil(num_top + 1.3 * num_height), image_data.size[1]])\n",
    "            num_right = np.amin([np.ceil(num_left + 1.3 * num_width), image_data.size[0]])\n",
    "            num_top = np.amax([np.floor(num_top - 0.3 * num_height), 0])\n",
    "            num_left = np.amax([np.floor(num_left - 0.3 * num_width), 0])         \n",
    "\n",
    "            # Cropping the expanded bounding box \n",
    "            image_data = image_data.crop((int(num_left), int(num_top), int(num_right), int(num_bottom))\\\n",
    "                                        ).resize([image_size,image_size])#.convert('L')\n",
    "        #Convert image to the grey scale and then normalize it\n",
    "        normalized_image = (np.array(image_data) - pixel_depth / 2)/ pixel_depth\n",
    "            \n",
    "        images[num_image, :, :,:] = normalized_image\n",
    "        \n",
    "        if not length:\n",
    "        # Isert blank category      \n",
    "            i = 3 - len(label)\n",
    "            if i > 0 :\n",
    "                label.extend([10.0]*i)\n",
    "            #labels.append(to_categorical(label,num_classes=11))\n",
    "            labels[num_image, :, :] =  to_categorical(label,num_classes=11)\n",
    "        else:\n",
    "            length_labels[num_image, :] = to_categorical(getLenNumber(data[\"boxes\"]), num_classes=5)\n",
    "        num_image += 1\n",
    "    \n",
    "    if length:\n",
    "        return images, length_labels    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_dataset(data, labels, positions, image_size = 54, length = False):\n",
    "    \n",
    "    k = 0\n",
    "    for i in range(len(data)):\n",
    "        if int(argmax(labels[i,1])) is 10:\n",
    "            k+=1\n",
    "    print(k)    \n",
    "    \n",
    "    new_dataset = np.ndarray(shape=(len(data)*positions +k* positions, image_size, image_size, 3),\n",
    "                         dtype=np.float32)\n",
    "    if not length:\n",
    "        new_labels = np.ndarray(shape=(len(data)*positions+k* positions, 3, 11))\n",
    "    else:\n",
    "        new_labels = np.ndarray(shape=(len(data)*positions+k* positions, 5)) \n",
    "    num_image = 0\n",
    "\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        pos = positions\n",
    "        if not length:\n",
    "            if int(argmax(labels[i,1])) is 10 :\n",
    "                pos = positions * 2\n",
    "\n",
    "        width = random.sample(range(10), pos)\n",
    "        heigth = random.sample(range(10), pos)\n",
    "\n",
    "        for j in range(pos):\n",
    "            new_dataset[num_image, :, :, :] = data[i, heigth[j]:heigth[j] + image_size, width[j]:width[j]+image_size, :]\n",
    "            new_labels[num_image] = labels[i]\n",
    "            #new_labels[num_image, :, :] = labels[i]\n",
    "            #new_labels[num_image, :] = labels[i]            \n",
    "            num_image += 1\n",
    "            \n",
    "    return new_dataset, new_labels       \n",
    "    #return new_dataset.reshape((-1, image_size, image_size, 1)), new_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training dataset generation and augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle_file(data):\n",
    "    with open(data, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#load data\n",
    "train_dataset = read_pickle_file(os.path.join(\"SVHN\",'training.pickle'))\n",
    "#generate and augment data\n",
    "train_data, train_labels = generate_dataset(train_dataset, 64)\n",
    "train_data, train_labels = augment_dataset(train_data, train_labels, 2)\n",
    "del train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmented train dataset shuffling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle train data\n",
    "idx = np.random.permutation(len(train_data))\n",
    "train_data = train_data[idx]\n",
    "train_labels  = train_labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation and testing datasets generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#load and prepare validation dataset\n",
    "validate_dataset = read_pickle_file(os.path.join(\"SVHN\",'validation.pickle'))\n",
    "test_dataset = read_pickle_file(os.path.join(\"SVHN\",'test.pickle'))\n",
    "\n",
    "test_data, test_labels = generate_dataset(test_dataset, True, 54)\n",
    "validate_data, validate_labels = generate_dataset(validate_dataset,True, 54)\n",
    "del validate_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated datasets saving in hdf5 format files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('D:/classifier_1.hdf5', 'w') as f:\n",
    "    #f.create_dataset(\"validate\", data= validate_data, compression=\"gzip\")\n",
    "    #f.create_dataset(\"validate labels\", data= validate_labels, compression=\"gzip\")\n",
    "    #f.create_dataset(\"train\", data= train_data, compression=\"gzip\")\n",
    "    #f.create_dataset(\"train labels\", data= train_labels, compression=\"gzip\")\n",
    "    f.create_dataset(\"test\", data=test_data, compression=\"gzip\")\n",
    "    f.create_dataset(\"test labels\", data=test_labels, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 ) SVHN  and other objects dataset preparation for classification model\n",
    "\n",
    "Like I mentioned before, we need our number classification approach to recognize if we aren't picturing a number. \n",
    "Therefore, we going to append images that don't contain a number and contain other objects from [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html), [Caltech 101](http://www.vision.caltech.edu/Image_Datasets/Caltech101/)  and [Caltech 256](http://www.vision.caltech.edu/Image_Datasets/Caltech256/) datasets with SVHN dataset. SVHN dataset will be generated the same way as in the first section, the only difference is that we include images that contain more than 3 digits numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) SVHN dataset generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read pickle files\n",
    "def read_pickle_file(data):\n",
    "    with open(data, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "# Set a new path of images.\n",
    "def set_new_file_path(data,new_path):\n",
    "    for i in range(len(data)):\n",
    "        data[i][\"filename\"] = os.path.join(new_path, data[i]['filename']) \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading data\n",
    "extra_data = read_pickle_file(os.path.join(\"SVHN\",\"extra\", 'extra.pickle'))\n",
    "train_data = read_pickle_file(os.path.join(\"SVHN\",\"train\", 'train.pickle'))\n",
    "test_data = read_pickle_file(os.path.join(\"SVHN\",\"test\", 'test.pickle'))\n",
    "\n",
    "extra_data = set_new_file_path(extra_data, os.path.join(\"SVHN\",\"extra\"))\n",
    "train_data = set_new_file_path(train_data, os.path.join(\"SVHN\",\"train\"))\n",
    "test_data = set_new_file_path(test_data, os.path.join(\"SVHN\",\"test\"))\n",
    "\n",
    "dataset  = extra_data + train_data + test_data\n",
    "del extra_data, train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering data\n",
    "def filter_data(data):\n",
    "    im_sizes = []; ind = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        skip = False\n",
    "        for j in range(len(data[i][\"boxes\"])):\n",
    "            if data[i][\"boxes\"][j][\"top\"] < 0 or data[i][\"boxes\"][j][\"left\"] < 0:\n",
    "                skip = True\n",
    "        # Skip pictures which contains more that 3 digits, first digit is 0 and wrong boxes coordinate \n",
    "        if int(data[i][\"boxes\"][0][\"label\"] == 10) or skip:\n",
    "            continue\n",
    "        ind.append(i)\n",
    "    return   ind\n",
    "\n",
    "# Getting images indexes and filtering data\n",
    "dataset_ind = filter_data(dataset)\n",
    "dataset = np.array(dataset)[dataset_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indexes(data_length, validate_size, is_test_ind = False, test_size = 0):\n",
    "\n",
    "    ind = np.arange(data_length)\n",
    "    validate_ind = np.random.choice(ind, validate_size, replace= False)\n",
    "    train_ind = np.delete(ind, validate_ind)\n",
    "    if not is_test_ind:\n",
    "        return validate_ind, train_ind\n",
    "    \n",
    "    test_ind = np.random.choice(train_ind, test_size, replace= False)\n",
    "    train_ind = np.setdiff1d(train_ind, test_ind)\n",
    "    return test_ind, validate_ind, train_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set test, validation and train dataset lenghts\n",
    "images_size = len(dataset)\n",
    "validate_size = 8000\n",
    "test_size = 4000\n",
    "test_ind, val_ind, train_ind =  get_indexes(len(dataset), validate_size, True, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Wall time: 12min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "SVHN_train_data_4, SVHN_train_length_4 = generate_dataset(dataset[train_ind], False, 64, True)\n",
    "SVHN_train_data_4, SVHN_train_length_4 = augment_dataset(SVHN_train_data_4,  SVHN_train_length_4, 2, 54, True)\n",
    "\n",
    "SVHN_validate_data_4, SVHN_validate_length_4 = generate_dataset(dataset[test_ind],True, 54, True)\n",
    "SVHN_test_data_4, SVHN_test_length_4 = generate_dataset(dataset[val_ind], True, 54, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) Object data preparation\n",
    "CIFAR images preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height, image_width = 54, 54\n",
    "first_file = True\n",
    "files = os.listdir(\"Cifar\")\n",
    "for file in files:\n",
    "    data = unpickle(os.path.join(\"Cifar\",file))\n",
    "    if first_file:\n",
    "        dataset = data[b\"data\"]\n",
    "        first_file = False\n",
    "    else:\n",
    "        dataset = np.append(dataset, data[b\"data\"], axis = 0)\n",
    "    \n",
    "dataset = dataset.reshape((-1, 3,32,32))\n",
    "dataset = np.swapaxes(dataset, 1, 2)\n",
    "dataset = np.swapaxes(dataset, 2, 3)    \n",
    "dataset = (dataset - 255.0/2) / 255.0\n",
    "\n",
    "cifar_data = np.ndarray(shape=(len(dataset), image_height, image_width, 3),\n",
    "                         dtype=np.float32)\n",
    "cifar_labels = np.array([to_categorical(0, num_classes=5)]*len(dataset)).reshape((-1,5))\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    cifar_data[i,:,:,:] = cv2.resize(dataset[i], ( image_width, image_height))\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 50000\n"
     ]
    }
   ],
   "source": [
    "print(len(cifar_data),len(cifar_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caltech 101 and Caltech 256 images preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_paths(primary_folder):\n",
    "    paths = []\n",
    "    folders = os.listdir(primary_folder )\n",
    "    for folder in folders:\n",
    "        files = os.listdir(os.path.join(primary_folder, folder))\n",
    "        for file in files:\n",
    "            paths.append(os.path.join(primary_folder, folder, file))\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get files paths\n",
    "obj256 = get_files_paths(\"256_ObjectCategories\")\n",
    "obj101 = get_files_paths(\"101_ObjectCategories\")\n",
    "paths = obj101 + obj256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13851\n",
      "29888\n",
      "Wall time: 2min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#2min 12s;\n",
    "def read_data(paths, image_width, image_height):\n",
    "    \n",
    "    pixel_depth = 255.0  # Number of levels per pixel. \n",
    "    half_pixel_depth = pixel_depth / 2\n",
    "    dataset = np.ndarray(shape=(len(paths), image_height, image_width, 3),\n",
    "                         dtype=np.float32)\n",
    "    j = 0\n",
    "    \n",
    "    for i in range(len(paths)):\n",
    "        try:\n",
    "            image = cv2.imread(paths[i])\n",
    "            shape = image.shape\n",
    "            if shape[0] < 70 or shape[1] < 110:\n",
    "                continue\n",
    "                \n",
    "            shape = image.shape\n",
    "            height = min(shape[0], random.randint(60,80))   \n",
    "            width = min(shape[1], random.randint(95,125))\n",
    "            y0 = random.randint(0, shape[0] - height)\n",
    "            x0 = random.randint(0, shape[1] - width)\n",
    "            \n",
    "            dataset[i, :, :, :] = (cv2.resize(image[y0:y0+height, x0:x0+width], \\\n",
    "                                              (image_width, image_height)) - half_pixel_depth) / pixel_depth\n",
    "            \n",
    "            #labels[i,:, :] = temp_label\n",
    "            #num_len[i, :] = temp_num_len\n",
    "            j += 1\n",
    "        except:\n",
    "            print(i)\n",
    "    labels = np.array([to_categorical(0, num_classes=5)]*j).reshape((-1,5))\n",
    "    \n",
    "    return dataset[:j], labels\n",
    "\n",
    "\n",
    "obj_data, obj_labels = read_data(paths, 54, 54)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR, Caltech 101 and Caltech 256 datasets merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_data = np.append(obj_data, cifar_data, axis = 0)\n",
    "obj_labels = np.append(obj_labels, cifar_labels, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3) SVHN and object dataset merging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will append object dataset to SVHN train, validate, and test dataset proportionately by their sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(SVHN_train_data_4)+len(SVHN_validate_data_4)+ len(SVHN_train_data_4)\n",
    "test_obj_size = int(len(SVHN_test_data_4)/total * len(obj_data))\n",
    "validate_obj_size = int(len(SVHN_validate_data_4)/total *  len(obj_data))\n",
    "test_ind, val_ind, train_ind =  get_indexes(len(obj_data), validate_size, True, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(data, labels):\n",
    "    idx = np.random.permutation(len(data))\n",
    "    data = data[idx]\n",
    "    labels  = labels[idx]\n",
    "    return data, labels\n",
    "\n",
    "def append_datasets(data1, data2, data1_labels, data2_labels):\n",
    "    data = np.concatenate((data1, data2), axis = 0)\n",
    "    data_labels = np.concatenate((data1_labels, data2_labels), axis = 0)\n",
    "    data, data_labels = shuffle_data(data, data_labels)\n",
    "    return data, data_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appending and writing validation and test datasets to the h2py files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_labels = append_datasets(SVHN_test_data_4, obj_data[test_ind],\n",
    "                                        SVHN_test_length_4, obj_labels[test_ind])\n",
    "validate_data, validate_labels = append_datasets( SVHN_validate_data_4, obj_data[val_ind],\n",
    "                                        SVHN_validate_length_4, obj_labels[val_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('D:/classifier_2.hdf5', 'w') as f:\n",
    "    f.create_dataset(\"validate\", data= validate_data, compression=\"gzip\")\n",
    "    f.create_dataset(\"validate labels\", data= validate_labels, compression=\"gzip\")\n",
    "    f.create_dataset(\"test\", data=test_data, compression=\"gzip\")\n",
    "    f.create_dataset(\"test labels\", data=test_labels, compression=\"gzip\")\n",
    "del validate_data, validate_labels, test_data, test_labels\n",
    "\n",
    "obj_data = obj_data[train_ind] \n",
    "obj_labels = obj_labels[train_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To append object and SVHN train datasets requires a lot of RAM which my computer 16GB doesn't enough to do so. We work this around by appending these datasets in h2py files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train labels merging  and shuffling\n",
    "train_labels = np.append(SVHN_train_length_4, obj_labels, axis = 0)\n",
    "ind = np.random.permutation(len(train_labels))\n",
    "train_labels  = train_labels[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving train dataset labels writing to the h2py files\n",
    "with h5py.File('D:/classifier_2.hdf5', 'a') as f:\n",
    "    f.create_dataset(\"train labels\", data= train_labels, compression=\"gzip\")\n",
    "del train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(indx, SVHN_data, obj_data, file_name, dataset_name, write = True):\n",
    "    data = np.ndarray(shape=(len(indx), 54, 54, 3),\n",
    "                         dtype=np.float32)\n",
    "    train_size = len(SVHN_data)\n",
    "    j = 0\n",
    "\n",
    "    for i in indx:\n",
    "    \n",
    "        if i >= train_size:\n",
    "            data[j] = obj_data[i-train_size]\n",
    "        else:\n",
    "            data[j] = SVHN_data[i]\n",
    "        j += 1\n",
    "    if write:\n",
    "        with h5py.File(file_name, 'a') as f:\n",
    "            f.create_dataset(dataset_name, data= data, compression=\"gzip\", maxshape=(None,54,54,3))\n",
    "    else: \n",
    "        with h5py.File(file_name, 'a') as f:\n",
    "            f[dataset_name].resize((f[dataset_name].shape[0] + data.shape[0]), axis = 0)\n",
    "            f[dataset_name][-data.shape[0]:] = data\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-22 15:53:21.446478\n",
      "2019-07-22 16:06:43.791616\n",
      "Wall time: 22min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#train images writing to the h2py files \n",
    "ind_m = int(len(ind)/2)\n",
    "print(datetime.datetime.now())\n",
    "create_dataset(ind[:ind_m], SVHN_train_data_4, obj_data, \"D:/classifier_2.hdf5\", \"train data\")\n",
    "print(datetime.datetime.now())\n",
    "create_dataset(ind[ind_m:], SVHN_train_data_4, obj_data, \"D:/classifier_2.hdf5\", \"train data\", write = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "394px",
    "left": "1088px",
    "right": "20px",
    "top": "114.012px",
    "width": "382px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
